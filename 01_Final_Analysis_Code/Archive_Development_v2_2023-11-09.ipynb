{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>회계년도</th>\n",
       "      <th>기업규모코드</th>\n",
       "      <th>업종코드</th>\n",
       "      <th>자산총계(요약)(백만원)</th>\n",
       "      <th>부채총계(요약)(백만원)</th>\n",
       "      <th>자본총계(요약)(백만원)</th>\n",
       "      <th>당기순이익(요약)(백만원)</th>\n",
       "      <th>주당순이익(요약)(원)</th>\n",
       "      <th>...</th>\n",
       "      <th>소각주식수(주)</th>\n",
       "      <th>소각금액(천원)</th>\n",
       "      <th>취득기간_From</th>\n",
       "      <th>취득기간_To</th>\n",
       "      <th>ROE(자기자본이익률)</th>\n",
       "      <th>토빈스큐_기업가치</th>\n",
       "      <th>Market</th>\n",
       "      <th>주식수_취득</th>\n",
       "      <th>주식수_처분</th>\n",
       "      <th>Behavior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2004/12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5179.0</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>2560.0</td>\n",
       "      <td>-3873.0</td>\n",
       "      <td>-395.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-74.782777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>651148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2005/12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8280.0</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>3419.0</td>\n",
       "      <td>-2558.0</td>\n",
       "      <td>-214.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-30.893720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>651148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2006/12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10030.0</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>7059.0</td>\n",
       "      <td>-3411.0</td>\n",
       "      <td>-724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-34.007976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>651148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2007/12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22074.0</td>\n",
       "      <td>1372.0</td>\n",
       "      <td>20701.0</td>\n",
       "      <td>-890.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.031893</td>\n",
       "      <td>1.000048</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>651148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2008/12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34557.0</td>\n",
       "      <td>9804.0</td>\n",
       "      <td>24753.0</td>\n",
       "      <td>-4659.0</td>\n",
       "      <td>-345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.482073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSDAQ</td>\n",
       "      <td>651148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30812</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>2018/12</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>782787.0</td>\n",
       "      <td>726055.0</td>\n",
       "      <td>56732.0</td>\n",
       "      <td>-96954.0</td>\n",
       "      <td>-576.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-12.385745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>1611742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>2019/12</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>386551.0</td>\n",
       "      <td>368919.0</td>\n",
       "      <td>17632.0</td>\n",
       "      <td>-52551.0</td>\n",
       "      <td>-400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.594843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>1611742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30814</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>2020/12</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>284767.0</td>\n",
       "      <td>304929.0</td>\n",
       "      <td>-20161.0</td>\n",
       "      <td>-37398.0</td>\n",
       "      <td>-323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.132842</td>\n",
       "      <td>1.000050</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>1611742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30815</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>2021/12</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>247990.0</td>\n",
       "      <td>139843.0</td>\n",
       "      <td>108147.0</td>\n",
       "      <td>15770.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.359127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>1611742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30816</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>2022/12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>293000.0</td>\n",
       "      <td>164975.0</td>\n",
       "      <td>128025.0</td>\n",
       "      <td>13942.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.758362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>KOSPI</td>\n",
       "      <td>1611742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30817 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            회사명  거래소코드     회계년도  기업규모코드  업종코드  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
       "0      (주)CMG제약  58820  2004/12    20.0     1         5179.0         2619.0   \n",
       "1      (주)CMG제약  58820  2005/12    20.0     1         8280.0         4861.0   \n",
       "2      (주)CMG제약  58820  2006/12    20.0     1        10030.0         2971.0   \n",
       "3      (주)CMG제약  58820  2007/12    20.0     1        22074.0         1372.0   \n",
       "4      (주)CMG제약  58820  2008/12    20.0     1        34557.0         9804.0   \n",
       "...         ...    ...      ...     ...   ...            ...            ...   \n",
       "30812   흥아해운(주)   3280  2018/12    30.0     1       782787.0       726055.0   \n",
       "30813   흥아해운(주)   3280  2019/12    30.0     1       386551.0       368919.0   \n",
       "30814   흥아해운(주)   3280  2020/12    30.0     1       284767.0       304929.0   \n",
       "30815   흥아해운(주)   3280  2021/12    30.0     1       247990.0       139843.0   \n",
       "30816   흥아해운(주)   3280  2022/12    10.0     1       293000.0       164975.0   \n",
       "\n",
       "       자본총계(요약)(백만원)  당기순이익(요약)(백만원)  주당순이익(요약)(원)  ...  소각주식수(주)  소각금액(천원)  \\\n",
       "0             2560.0         -3873.0        -395.0  ...       0.0       0.0   \n",
       "1             3419.0         -2558.0        -214.0  ...       0.0       0.0   \n",
       "2             7059.0         -3411.0        -724.0  ...       0.0       0.0   \n",
       "3            20701.0          -890.0         -74.0  ...       0.0       0.0   \n",
       "4            24753.0         -4659.0        -345.0  ...       0.0       0.0   \n",
       "...              ...             ...           ...  ...       ...       ...   \n",
       "30812        56732.0        -96954.0        -576.0  ...       0.0       0.0   \n",
       "30813        17632.0        -52551.0        -400.0  ...       0.0       0.0   \n",
       "30814       -20161.0        -37398.0        -323.0  ...       0.0       0.0   \n",
       "30815       108147.0         15770.0         113.0  ...       0.0       0.0   \n",
       "30816       128025.0         13942.0          58.0  ...       0.0       0.0   \n",
       "\n",
       "      취득기간_From  취득기간_To  ROE(자기자본이익률) 토빈스큐_기업가치  Market     주식수_취득  주식수_처분  \\\n",
       "0             0        0    -74.782777  1.000000  KOSDAQ   651148.0     0.0   \n",
       "1             0        0    -30.893720  1.000000  KOSDAQ   651148.0     0.0   \n",
       "2             0        0    -34.007976  1.000000  KOSDAQ   651148.0     0.0   \n",
       "3             0        0     -4.031893  1.000048  KOSDAQ   651148.0     0.0   \n",
       "4             0        0    -13.482073  1.000000  KOSDAQ   651148.0     0.0   \n",
       "...         ...      ...           ...       ...     ...        ...     ...   \n",
       "30812         0        0    -12.385745  1.000000   KOSPI  1611742.0     0.0   \n",
       "30813         0        0    -13.594843  1.000000   KOSPI  1611742.0     0.0   \n",
       "30814         0        0    -13.132842  1.000050   KOSPI  1611742.0     0.0   \n",
       "30815         0        0      6.359127  1.000000   KOSPI  1611742.0     0.0   \n",
       "30816         0        0      4.758362  1.000000   KOSPI  1611742.0     0.0   \n",
       "\n",
       "                Behavior  \n",
       "0      Long-term Holding  \n",
       "1      Long-term Holding  \n",
       "2      Long-term Holding  \n",
       "3      Long-term Holding  \n",
       "4      Long-term Holding  \n",
       "...                  ...  \n",
       "30812  Long-term Holding  \n",
       "30813  Long-term Holding  \n",
       "30814  Long-term Holding  \n",
       "30815  Long-term Holding  \n",
       "30816  Long-term Holding  \n",
       "\n",
       "[30817 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 파일을 불러오기\n",
    "file_path = './merged_data.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except Exception as e:\n",
    "    df = None, str(e)   \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 기본 통계와 구조를 확인합니다.  \n",
    "\n",
    "DBSCAN 클러스터링을 적용합니다.  \n",
    "\n",
    "클러스터링 결과를 바탕으로 머신러닝 분류를 실행합니다.  \n",
    "\n",
    "'behavior' 변수를 특별히 분석합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '취득기간_From'을 datetime 타입으로 변환 (가정: 이 컬럼이 이미 존재한다고 가정)\n",
    "df['취득기간_From'] = pd.to_datetime(df['취득기간_From'], errors='coerce')\n",
    "df['취득기간_To'] = pd.to_datetime(df['취득기간_To'], errors='coerce')\n",
    "# '취득간극' 컬럼 생성\n",
    "df['취득간극'] = (df['취득기간_To'] - df['취득기간_From']).dt.days\n",
    "df['취득간극'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '회계년도', '기업규모코드', '업종코드', '자산총계(요약)(백만원)',\n",
       "       '부채총계(요약)(백만원)', '자본총계(요약)(백만원)', '당기순이익(요약)(백만원)', '주당순이익(요약)(원)',\n",
       "       '발행주식수(*)(연결)(주)', '구분', '소각일', '소각주식수(주)', '소각금액(천원)', '취득기간_From',\n",
       "       '취득기간_To', 'ROE(자기자본이익률)', '토빈스큐_기업가치', 'Market', '주식수_취득', '주식수_처분',\n",
       "       'Behavior', '취득간극'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long-term Holding    11794\n",
       "Disposed_Slower       8548\n",
       "Disposed_Faster       8517\n",
       "Burned                1942\n",
       "Name: Behavior, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 결측값 제거\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# 'Behavior' 변수가 'Behavior_Unknown'인 행 삭제\n",
    "data_filtered = data_clean[data_clean['Behavior'] != 'Unknown']\n",
    "\n",
    "# 확인\n",
    "data_filtered['Behavior'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0        20.0\n",
       "1        20.0\n",
       "2        20.0\n",
       "3        20.0\n",
       "4        20.0\n",
       "         ... \n",
       "30812    30.0\n",
       "30813    30.0\n",
       "30814    30.0\n",
       "30815    30.0\n",
       "30816    10.0\n",
       "Name: 기업규모코드, Length: 30801, dtype: float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered['기업규모코드'].value_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        회사명  거래소코드     회계년도  기업규모코드  업종코드  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
      "0  (주)CMG제약  58820  2004/12    20.0     1         5179.0         2619.0   \n",
      "1  (주)CMG제약  58820  2005/12    20.0     1         8280.0         4861.0   \n",
      "2  (주)CMG제약  58820  2006/12    20.0     1        10030.0         2971.0   \n",
      "3  (주)CMG제약  58820  2007/12    20.0     1        22074.0         1372.0   \n",
      "4  (주)CMG제약  58820  2008/12    20.0     1        34557.0         9804.0   \n",
      "\n",
      "   자본총계(요약)(백만원)  당기순이익(요약)(백만원)  주당순이익(요약)(원)  ...  토빈스큐_기업가치  Market  \\\n",
      "0         2560.0         -3873.0        -395.0  ...   1.000000  KOSDAQ   \n",
      "1         3419.0         -2558.0        -214.0  ...   1.000000  KOSDAQ   \n",
      "2         7059.0         -3411.0        -724.0  ...   1.000000  KOSDAQ   \n",
      "3        20701.0          -890.0         -74.0  ...   1.000048  KOSDAQ   \n",
      "4        24753.0         -4659.0        -345.0  ...   1.000000  KOSDAQ   \n",
      "\n",
      "     주식수_취득  주식수_처분           Behavior 기업규모_0.0 기업규모_10.0  기업규모_20.0  \\\n",
      "0  651148.0     0.0  Long-term Holding        0         0          1   \n",
      "1  651148.0     0.0  Long-term Holding        0         0          1   \n",
      "2  651148.0     0.0  Long-term Holding        0         0          1   \n",
      "3  651148.0     0.0  Long-term Holding        0         0          1   \n",
      "4  651148.0     0.0  Long-term Holding        0         0          1   \n",
      "\n",
      "   기업규모_30.0 기업규모_90.0  \n",
      "0          0         0  \n",
      "1          0         0  \n",
      "2          0         0  \n",
      "3          0         0  \n",
      "4          0         0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩을 수행하고 결과를 새로운 데이터프레임에 할당합니다.\n",
    "one_hot_encoded = pd.get_dummies(data_filtered['기업규모코드'], prefix='기업규모')\n",
    "\n",
    "# 원-핫 인코딩된 데이터프레임을 원본 데이터프레임에 결합합니다.\n",
    "data_filtered = data_filtered.join(one_hot_encoded)\n",
    "\n",
    "# 결과를 확인합니다.\n",
    "print(data_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        회사명  거래소코드     회계년도  업종코드  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
      "0  (주)CMG제약  58820  2004/12     1         5179.0         2619.0   \n",
      "1  (주)CMG제약  58820  2005/12     1         8280.0         4861.0   \n",
      "2  (주)CMG제약  58820  2006/12     1        10030.0         2971.0   \n",
      "3  (주)CMG제약  58820  2007/12     1        22074.0         1372.0   \n",
      "4  (주)CMG제약  58820  2008/12     1        34557.0         9804.0   \n",
      "\n",
      "   자본총계(요약)(백만원)  당기순이익(요약)(백만원)  주당순이익(요약)(원)  발행주식수(*)(연결)(주)  ...  \\\n",
      "0         2560.0         -3873.0        -395.0              0.0  ...   \n",
      "1         3419.0         -2558.0        -214.0              0.0  ...   \n",
      "2         7059.0         -3411.0        -724.0              0.0  ...   \n",
      "3        20701.0          -890.0         -74.0              0.0  ...   \n",
      "4        24753.0         -4659.0        -345.0              0.0  ...   \n",
      "\n",
      "   토빈스큐_기업가치  Market    주식수_취득  주식수_처분           Behavior 기업규모_0.0  기업규모_10.0  \\\n",
      "0   1.000000  KOSDAQ  651148.0     0.0  Long-term Holding        0          0   \n",
      "1   1.000000  KOSDAQ  651148.0     0.0  Long-term Holding        0          0   \n",
      "2   1.000000  KOSDAQ  651148.0     0.0  Long-term Holding        0          0   \n",
      "3   1.000048  KOSDAQ  651148.0     0.0  Long-term Holding        0          0   \n",
      "4   1.000000  KOSDAQ  651148.0     0.0  Long-term Holding        0          0   \n",
      "\n",
      "   기업규모_20.0 기업규모_30.0  기업규모_90.0  \n",
      "0          1         0          0  \n",
      "1          1         0          0  \n",
      "2          1         0          0  \n",
      "3          1         0          0  \n",
      "4          1         0          0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# '기업규모코드' 열을 삭제합니다.\n",
    "data_filtered = data_filtered.drop('기업규모코드', axis=1)\n",
    "\n",
    "# 결과를 확인합니다.\n",
    "print(data_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TobinsQ_Label'] = (data['토빈스큐_기업가치'] >= 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Total_Count</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Burned</td>\n",
       "      <td>1942</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disposed_Faster</td>\n",
       "      <td>8517</td>\n",
       "      <td>0.999414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disposed_Slower</td>\n",
       "      <td>8548</td>\n",
       "      <td>1.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>11794</td>\n",
       "      <td>0.999917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Behavior  Total_Count      mean\n",
       "0             Burned         1942  1.000000\n",
       "1    Disposed_Faster         8517  0.999414\n",
       "2    Disposed_Slower         8548  1.000003\n",
       "3  Long-term Holding        11794  0.999917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Behavior' 범주에 따라 데이터를 그룹화하고, 각 그룹에서 토빈스 Q 값이 1 이상인 비율을 계산\n",
    "behavior_grouped = data.groupby('Behavior')['토빈스큐_기업가치'].agg(['count', 'mean'])\n",
    "# behavior_grouped['mean'] = behavior_grouped['sum'] / behavior_grouped['count']\n",
    "\n",
    "behavior_grouped.reset_index(inplace=True)\n",
    "behavior_grouped.rename(columns={'count': 'Total_Count', 'sum': 'Count_of_TobinsQ_Above_1', 'ratio': 'Ratio_of_TobinsQ_Above_1'}, inplace=True)\n",
    "behavior_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # 수치형 변수만 선택\n",
    "# numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# # 데이터 분포 시각화\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# sns.boxplot(data=data[numeric_columns])\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Boxplot of Numeric Features')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '회계년도', '기업규모코드', '업종코드', '자산총계(요약)(백만원)',\n",
       "       '부채총계(요약)(백만원)', '자본총계(요약)(백만원)', '당기순이익(요약)(백만원)', '주당순이익(요약)(원)',\n",
       "       '발행주식수(*)(연결)(주)', '구분', '소각일', '소각주식수(주)', '소각금액(천원)', '취득기간_From',\n",
       "       '취득기간_To', 'ROE(자기자본이익률)', '토빈스큐_기업가치', 'Market', '주식수_취득', '주식수_처분',\n",
       "       'Behavior', '취득간극'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1766308047.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected['Market'] = label_encoder.fit_transform(data_selected['Market'])\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1766308047.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected[numerical_columns] = scaler.fit_transform(data_selected[numerical_columns])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>업종코드</th>\n",
       "      <th>Market</th>\n",
       "      <th>자산총계(요약)(백만원)</th>\n",
       "      <th>부채총계(요약)(백만원)</th>\n",
       "      <th>자본총계(요약)(백만원)</th>\n",
       "      <th>당기순이익(요약)(백만원)</th>\n",
       "      <th>ROE(자기자본이익률)</th>\n",
       "      <th>발행주식수(*)(연결)(주)</th>\n",
       "      <th>...</th>\n",
       "      <th>소각금액(천원)</th>\n",
       "      <th>주식수_취득</th>\n",
       "      <th>주식수_처분</th>\n",
       "      <th>기업규모_0.0</th>\n",
       "      <th>기업규모_10.0</th>\n",
       "      <th>기업규모_20.0</th>\n",
       "      <th>기업규모_30.0</th>\n",
       "      <th>기업규모_90.0</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>토빈스큐_기업가치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140674</td>\n",
       "      <td>-0.106036</td>\n",
       "      <td>-0.143391</td>\n",
       "      <td>-0.087043</td>\n",
       "      <td>-1.480690</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.307758</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140368</td>\n",
       "      <td>-0.105754</td>\n",
       "      <td>-0.143181</td>\n",
       "      <td>-0.084630</td>\n",
       "      <td>-0.623225</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.307758</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140196</td>\n",
       "      <td>-0.105992</td>\n",
       "      <td>-0.142291</td>\n",
       "      <td>-0.086195</td>\n",
       "      <td>-0.684068</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.307758</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.139011</td>\n",
       "      <td>-0.106193</td>\n",
       "      <td>-0.138955</td>\n",
       "      <td>-0.081569</td>\n",
       "      <td>-0.098422</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.307758</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137782</td>\n",
       "      <td>-0.105132</td>\n",
       "      <td>-0.137965</td>\n",
       "      <td>-0.088486</td>\n",
       "      <td>-0.283052</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.307758</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30812</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>-0.015026</td>\n",
       "      <td>-0.130146</td>\n",
       "      <td>-0.257867</td>\n",
       "      <td>-0.261632</td>\n",
       "      <td>1.377484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.270044</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.103140</td>\n",
       "      <td>-0.059955</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>-0.176378</td>\n",
       "      <td>-0.285255</td>\n",
       "      <td>0.787190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.270044</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30814</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.113157</td>\n",
       "      <td>-0.068005</td>\n",
       "      <td>-0.148946</td>\n",
       "      <td>-0.148569</td>\n",
       "      <td>-0.276229</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.270044</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30815</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.116777</td>\n",
       "      <td>-0.088773</td>\n",
       "      <td>-0.117575</td>\n",
       "      <td>-0.050994</td>\n",
       "      <td>0.104588</td>\n",
       "      <td>1.979397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.270044</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30816</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.112347</td>\n",
       "      <td>-0.085611</td>\n",
       "      <td>-0.112715</td>\n",
       "      <td>-0.054349</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>1.979397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012688</td>\n",
       "      <td>-0.270044</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30801 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            회사명  거래소코드  업종코드  Market  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
       "0      (주)CMG제약  58820     1       0      -0.140674      -0.106036   \n",
       "1      (주)CMG제약  58820     1       0      -0.140368      -0.105754   \n",
       "2      (주)CMG제약  58820     1       0      -0.140196      -0.105992   \n",
       "3      (주)CMG제약  58820     1       0      -0.139011      -0.106193   \n",
       "4      (주)CMG제약  58820     1       0      -0.137782      -0.105132   \n",
       "...         ...    ...   ...     ...            ...            ...   \n",
       "30812   흥아해운(주)   3280     1       1      -0.064143      -0.015026   \n",
       "30813   흥아해운(주)   3280     1       1      -0.103140      -0.059955   \n",
       "30814   흥아해운(주)   3280     1       1      -0.113157      -0.068005   \n",
       "30815   흥아해운(주)   3280     1       1      -0.116777      -0.088773   \n",
       "30816   흥아해운(주)   3280     1       1      -0.112347      -0.085611   \n",
       "\n",
       "       자본총계(요약)(백만원)  당기순이익(요약)(백만원)  ROE(자기자본이익률)  발행주식수(*)(연결)(주)  ...  \\\n",
       "0          -0.143391       -0.087043     -1.480690        -0.254495  ...   \n",
       "1          -0.143181       -0.084630     -0.623225        -0.254495  ...   \n",
       "2          -0.142291       -0.086195     -0.684068        -0.254495  ...   \n",
       "3          -0.138955       -0.081569     -0.098422        -0.254495  ...   \n",
       "4          -0.137965       -0.088486     -0.283052        -0.254495  ...   \n",
       "...              ...             ...           ...              ...  ...   \n",
       "30812      -0.130146       -0.257867     -0.261632         1.377484  ...   \n",
       "30813      -0.139706       -0.176378     -0.285255         0.787190  ...   \n",
       "30814      -0.148946       -0.148569     -0.276229         0.830118  ...   \n",
       "30815      -0.117575       -0.050994      0.104588         1.979397  ...   \n",
       "30816      -0.112715       -0.054349      0.073314         1.979397  ...   \n",
       "\n",
       "       소각금액(천원)    주식수_취득    주식수_처분  기업규모_0.0  기업규모_10.0  기업규모_20.0  \\\n",
       "0     -0.012688 -0.307758 -0.296076         0          0          1   \n",
       "1     -0.012688 -0.307758 -0.296076         0          0          1   \n",
       "2     -0.012688 -0.307758 -0.296076         0          0          1   \n",
       "3     -0.012688 -0.307758 -0.296076         0          0          1   \n",
       "4     -0.012688 -0.307758 -0.296076         0          0          1   \n",
       "...         ...       ...       ...       ...        ...        ...   \n",
       "30812 -0.012688 -0.270044 -0.296076         0          0          0   \n",
       "30813 -0.012688 -0.270044 -0.296076         0          0          0   \n",
       "30814 -0.012688 -0.270044 -0.296076         0          0          0   \n",
       "30815 -0.012688 -0.270044 -0.296076         0          0          0   \n",
       "30816 -0.012688 -0.270044 -0.296076         0          1          0   \n",
       "\n",
       "       기업규모_30.0  기업규모_90.0           Behavior  토빈스큐_기업가치  \n",
       "0              0          0  Long-term Holding   1.000000  \n",
       "1              0          0  Long-term Holding   1.000000  \n",
       "2              0          0  Long-term Holding   1.000000  \n",
       "3              0          0  Long-term Holding   1.000048  \n",
       "4              0          0  Long-term Holding   1.000000  \n",
       "...          ...        ...                ...        ...  \n",
       "30812          1          0  Long-term Holding   1.000000  \n",
       "30813          1          0  Long-term Holding   1.000000  \n",
       "30814          1          0  Long-term Holding   1.000050  \n",
       "30815          1          0  Long-term Holding   1.000000  \n",
       "30816          0          0  Long-term Holding   1.000000  \n",
       "\n",
       "[30801 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting relevant variables\n",
    "selected_columns = [\n",
    "    '회사명', '거래소코드', '업종코드', 'Market', \n",
    "    '자산총계(요약)(백만원)', '부채총계(요약)(백만원)', '자본총계(요약)(백만원)', \n",
    "    '당기순이익(요약)(백만원)', 'ROE(자기자본이익률)', '발행주식수(*)(연결)(주)','구분', \n",
    "    '소각주식수(주)', '소각금액(천원)', '주식수_취득', '주식수_처분','기업규모_0.0','기업규모_10.0','기업규모_20.0','기업규모_30.0','기업규모_90.0',\n",
    "    'Behavior', '토빈스큐_기업가치'\n",
    "]\n",
    "data_selected = data[selected_columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Identify duplicate columns\n",
    "label_encoder = LabelEncoder()\n",
    "data_selected['Market'] = label_encoder.fit_transform(data_selected['Market'])\n",
    "\n",
    "numerical_columns = [\n",
    "    '자산총계(요약)(백만원)', '부채총계(요약)(백만원)', '자본총계(요약)(백만원)', \n",
    "    '당기순이익(요약)(백만원)', 'ROE(자기자본이익률)', '발행주식수(*)(연결)(주)',\n",
    "    '소각주식수(주)', '소각금액(천원)', '주식수_취득', '주식수_처분'\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "data_selected[numerical_columns] = scaler.fit_transform(data_selected[numerical_columns])\n",
    "\n",
    "data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "30812    1\n",
       "30813    1\n",
       "30814    1\n",
       "30815    1\n",
       "30816    1\n",
       "Name: Market, Length: 30801, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected['Market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['회사명', '거래소코드', '업종코드', 'Market', '자산총계(요약)(백만원)', '부채총계(요약)(백만원)',\n",
       "       '자본총계(요약)(백만원)', '당기순이익(요약)(백만원)', 'ROE(자기자본이익률)', '발행주식수(*)(연결)(주)',\n",
       "       '구분', '소각주식수(주)', '소각금액(천원)', '주식수_취득', '주식수_처분', '기업규모_0.0',\n",
       "       '기업규모_10.0', '기업규모_20.0', '기업규모_30.0', '기업규모_90.0', 'Behavior',\n",
       "       '토빈스큐_기업가치'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Selecting columns for hierarchical clustering\n",
    "\n",
    "\n",
    "clustering_columns = [\n",
    "'자산총계(요약)(백만원)', '부채총계(요약)(백만원)',\n",
    "       '자본총계(요약)(백만원)', '당기순이익(요약)(백만원)', 'ROE(자기자본이익률)','구분','Market'\n",
    "\n",
    "]\n",
    "# # '부채총계(요약)(백만원)', '자본총계(요약)(백만원)', \n",
    "# #     '당기순이익(요약)(백만원)','ROE(자기자본이익률)', \n",
    "#     '소각주식수(주)', '소각금액(천원)', '주식수_취득', '발행주식수(*)(연결)(주)','주식수_처분','구분', 'Market',\n",
    "# ]\n",
    "# Due to computational limitations, let's take a subset of the data for demonstration\n",
    "\n",
    "data_subset = data_selected[clustering_columns]\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data_subset)\n",
    "# Elbow Method를 사용하여 최적의 클러스터 수 찾기\n",
    "inertia = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "    kmeans.fit(scaled_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Elbow 그래프 그리기\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal Number of Clusters')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsookim/opt/anaconda3/envs/your_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 2, 2, 2], dtype=int32), 0.7470350066355882)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#KMeans 클러스터링\n",
    "# 클러스터 수를 5로 설정 (임의로 설정, 이후에 최적의 클러스터 수를 찾을 수 있음)\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(scaled_data )\n",
    "\n",
    "# 결과 레이블\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 실루엣 스코어 계산\n",
    "silhouette_avg = silhouette_score(scaled_data, labels)\n",
    "\n",
    "labels, silhouette_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1264379296.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_subset['Cluster_Labels'] = kmeans.labels_\n"
     ]
    }
   ],
   "source": [
    "data_subset['Cluster_Labels'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "30812    2\n",
       "30813    2\n",
       "30814    2\n",
       "30815    2\n",
       "30816    2\n",
       "Name: Cluster_Labels, Length: 30801, dtype: int32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset['Cluster_Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>자산총계(요약)(백만원)</th>\n",
       "      <th>부채총계(요약)(백만원)</th>\n",
       "      <th>자본총계(요약)(백만원)</th>\n",
       "      <th>당기순이익(요약)(백만원)</th>\n",
       "      <th>ROE(자기자본이익률)</th>\n",
       "      <th>구분</th>\n",
       "      <th>Market</th>\n",
       "      <th>Cluster_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.140674</td>\n",
       "      <td>-0.106036</td>\n",
       "      <td>-0.143391</td>\n",
       "      <td>-0.087043</td>\n",
       "      <td>-1.480690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.140368</td>\n",
       "      <td>-0.105754</td>\n",
       "      <td>-0.143181</td>\n",
       "      <td>-0.084630</td>\n",
       "      <td>-0.623225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.140196</td>\n",
       "      <td>-0.105992</td>\n",
       "      <td>-0.142291</td>\n",
       "      <td>-0.086195</td>\n",
       "      <td>-0.684068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139011</td>\n",
       "      <td>-0.106193</td>\n",
       "      <td>-0.138955</td>\n",
       "      <td>-0.081569</td>\n",
       "      <td>-0.098422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.137782</td>\n",
       "      <td>-0.105132</td>\n",
       "      <td>-0.137965</td>\n",
       "      <td>-0.088486</td>\n",
       "      <td>-0.283052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18634</th>\n",
       "      <td>-0.056474</td>\n",
       "      <td>-0.081127</td>\n",
       "      <td>0.017375</td>\n",
       "      <td>0.030444</td>\n",
       "      <td>0.116871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18635</th>\n",
       "      <td>-0.057722</td>\n",
       "      <td>-0.080186</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>-0.018089</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18636</th>\n",
       "      <td>-0.056148</td>\n",
       "      <td>-0.082334</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>-0.031010</td>\n",
       "      <td>0.040630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18637</th>\n",
       "      <td>-0.057630</td>\n",
       "      <td>-0.085147</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>0.079928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18638</th>\n",
       "      <td>-0.059835</td>\n",
       "      <td>-0.085422</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>-0.028643</td>\n",
       "      <td>0.046411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18623 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       자산총계(요약)(백만원)  부채총계(요약)(백만원)  자본총계(요약)(백만원)  당기순이익(요약)(백만원)  \\\n",
       "0          -0.140674      -0.106036      -0.143391       -0.087043   \n",
       "1          -0.140368      -0.105754      -0.143181       -0.084630   \n",
       "2          -0.140196      -0.105992      -0.142291       -0.086195   \n",
       "3          -0.139011      -0.106193      -0.138955       -0.081569   \n",
       "4          -0.137782      -0.105132      -0.137965       -0.088486   \n",
       "...              ...            ...            ...             ...   \n",
       "18634      -0.056474      -0.081127       0.017375        0.030444   \n",
       "18635      -0.057722      -0.080186       0.012444       -0.018089   \n",
       "18636      -0.056148      -0.082334       0.020530       -0.031010   \n",
       "18637      -0.057630      -0.085147       0.022314       -0.000524   \n",
       "18638      -0.059835      -0.085422       0.017372       -0.028643   \n",
       "\n",
       "       ROE(자기자본이익률)   구분  Market  Cluster_Labels  \n",
       "0         -1.480690  0.0       0               0  \n",
       "1         -0.623225  0.0       0               0  \n",
       "2         -0.684068  0.0       0               0  \n",
       "3         -0.098422  0.0       0               0  \n",
       "4         -0.283052  0.0       0               0  \n",
       "...             ...  ...     ...             ...  \n",
       "18634      0.116871  0.0       0               0  \n",
       "18635      0.057988  0.0       0               0  \n",
       "18636      0.040630  0.0       0               0  \n",
       "18637      0.079928  0.0       0               0  \n",
       "18638      0.046411  0.0       0               0  \n",
       "\n",
       "[18623 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset[data_subset['Cluster_Labels']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cluster_Labels'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/814753932.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  data.groupby('Cluster_Labels').mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>업종코드</th>\n",
       "      <th>자산총계(요약)(백만원)</th>\n",
       "      <th>부채총계(요약)(백만원)</th>\n",
       "      <th>자본총계(요약)(백만원)</th>\n",
       "      <th>당기순이익(요약)(백만원)</th>\n",
       "      <th>주당순이익(요약)(원)</th>\n",
       "      <th>발행주식수(*)(연결)(주)</th>\n",
       "      <th>구분</th>\n",
       "      <th>소각주식수(주)</th>\n",
       "      <th>...</th>\n",
       "      <th>ROE(자기자본이익률)</th>\n",
       "      <th>토빈스큐_기업가치</th>\n",
       "      <th>주식수_취득</th>\n",
       "      <th>주식수_처분</th>\n",
       "      <th>기업규모_0.0</th>\n",
       "      <th>기업규모_10.0</th>\n",
       "      <th>기업규모_20.0</th>\n",
       "      <th>기업규모_30.0</th>\n",
       "      <th>기업규모_90.0</th>\n",
       "      <th>TobinsQ_Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster_Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92706.888793</td>\n",
       "      <td>1.122698</td>\n",
       "      <td>1.280631e+05</td>\n",
       "      <td>5.295187e+04</td>\n",
       "      <td>7.511121e+04</td>\n",
       "      <td>3.690261e+03</td>\n",
       "      <td>1451.456586</td>\n",
       "      <td>1.502930e+07</td>\n",
       "      <td>0.571337</td>\n",
       "      <td>12021.523815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>4.704992e+06</td>\n",
       "      <td>1.241109e+06</td>\n",
       "      <td>0.065671</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>0.631316</td>\n",
       "      <td>0.262256</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.133867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21754.301075</td>\n",
       "      <td>1.763441</td>\n",
       "      <td>1.450465e+08</td>\n",
       "      <td>9.850756e+07</td>\n",
       "      <td>4.653892e+07</td>\n",
       "      <td>5.189126e+06</td>\n",
       "      <td>22203.870968</td>\n",
       "      <td>7.551195e+08</td>\n",
       "      <td>2.365591</td>\n",
       "      <td>124731.182796</td>\n",
       "      <td>...</td>\n",
       "      <td>5.422030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.238434e+08</td>\n",
       "      <td>9.139443e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.204301</td>\n",
       "      <td>0.376344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36876.350021</td>\n",
       "      <td>1.170211</td>\n",
       "      <td>2.342633e+06</td>\n",
       "      <td>1.315256e+06</td>\n",
       "      <td>1.027377e+06</td>\n",
       "      <td>6.539234e+04</td>\n",
       "      <td>2881.473066</td>\n",
       "      <td>4.083840e+07</td>\n",
       "      <td>0.914357</td>\n",
       "      <td>42123.106661</td>\n",
       "      <td>...</td>\n",
       "      <td>2.082456</td>\n",
       "      <td>0.999917</td>\n",
       "      <td>1.343465e+07</td>\n",
       "      <td>3.769351e+06</td>\n",
       "      <td>0.034671</td>\n",
       "      <td>0.240050</td>\n",
       "      <td>0.162433</td>\n",
       "      <td>0.526272</td>\n",
       "      <td>0.036574</td>\n",
       "      <td>0.130161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       거래소코드      업종코드  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
       "Cluster_Labels                                                         \n",
       "0               92706.888793  1.122698   1.280631e+05   5.295187e+04   \n",
       "1               21754.301075  1.763441   1.450465e+08   9.850756e+07   \n",
       "2               36876.350021  1.170211   2.342633e+06   1.315256e+06   \n",
       "\n",
       "                자본총계(요약)(백만원)  당기순이익(요약)(백만원)  주당순이익(요약)(원)  발행주식수(*)(연결)(주)  \\\n",
       "Cluster_Labels                                                                 \n",
       "0                7.511121e+04    3.690261e+03   1451.456586     1.502930e+07   \n",
       "1                4.653892e+07    5.189126e+06  22203.870968     7.551195e+08   \n",
       "2                1.027377e+06    6.539234e+04   2881.473066     4.083840e+07   \n",
       "\n",
       "                      구분       소각주식수(주)  ...  ROE(자기자본이익률)  토빈스큐_기업가치  \\\n",
       "Cluster_Labels                           ...                            \n",
       "0               0.571337   12021.523815  ...      0.285100   0.999735   \n",
       "1               2.365591  124731.182796  ...      5.422030   1.000000   \n",
       "2               0.914357   42123.106661  ...      2.082456   0.999917   \n",
       "\n",
       "                      주식수_취득        주식수_처분  기업규모_0.0  기업규모_10.0  기업규모_20.0  \\\n",
       "Cluster_Labels                                                               \n",
       "0               4.704992e+06  1.241109e+06  0.065671   0.025184   0.631316   \n",
       "1               1.238434e+08  9.139443e+06  0.000000   0.720430   0.010753   \n",
       "2               1.343465e+07  3.769351e+06  0.034671   0.240050   0.162433   \n",
       "\n",
       "                기업규모_30.0  기업규모_90.0  TobinsQ_Label  \n",
       "Cluster_Labels                                       \n",
       "0                0.262256   0.015572       0.133867  \n",
       "1                0.064516   0.204301       0.376344  \n",
       "2                0.526272   0.036574       0.130161  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Cluster_Labels').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_33658/125323683.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  data.groupby('Cluster_Labels').mean().to_csv('기업규모고려.csv',index=False)\n"
     ]
    }
   ],
   "source": [
    "#data.groupby('Cluster_Labels').mean().to_csv('기업규모고려.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_selected.groupby('Cluster_Labels').mean().to_csv('cluster4_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클러스터 라벨별 변수들 요약 통계량 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 각 클러스터에 대한 토빈스 큐 기업가치의 통계를 계산\n",
    "# data_selected['Cluster_Labels'] =kmeans.labels_\n",
    "# cluster_tobin_stats = data_selected.groupby('Cluster_Labels')['토빈스큐_기업가치'].agg(['mean', 'std', 'median','count']).reset_index()\n",
    "# cluster_behavior_stats = data_selected.groupby('Cluster_Labels')['Behavior'].agg(['count']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_Labels</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>7558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Disposed_Slower</td>\n",
       "      <td>5102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Disposed_Faster</td>\n",
       "      <td>5210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Burned</td>\n",
       "      <td>753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>4228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Disposed_Slower</td>\n",
       "      <td>3446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Disposed_Faster</td>\n",
       "      <td>3259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Burned</td>\n",
       "      <td>1152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Disposed_Slower</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Disposed_Faster</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Burned</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cluster_Labels           Behavior   Count\n",
       "0                0  Long-term Holding  7558.0\n",
       "1                0    Disposed_Slower  5102.0\n",
       "2                0    Disposed_Faster  5210.0\n",
       "3                0             Burned   753.0\n",
       "4                2  Long-term Holding  4228.0\n",
       "5                2    Disposed_Slower  3446.0\n",
       "6                2    Disposed_Faster  3259.0\n",
       "7                2             Burned  1152.0\n",
       "8                1  Long-term Holding     8.0\n",
       "9                1    Disposed_Slower     0.0\n",
       "10               1    Disposed_Faster    48.0\n",
       "11               1             Burned    37.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 클러스터별로 각 Behavior의 개수를 세는 작업\n",
    "cluster_behavior_stats = data.groupby(['Cluster_Labels', 'Behavior']).size().reset_index(name='Count')\n",
    "\n",
    "# 16개의 행을 갖도록 누락된 행을 채워넣는 작업\n",
    "all_clusters = data['Cluster_Labels'].unique()\n",
    "all_behaviors = data['Behavior'].unique()\n",
    "all_combinations = [(c, b) for c in all_clusters for b in all_behaviors]\n",
    "\n",
    "complete_cluster_behavior_stats = pd.DataFrame(all_combinations, columns=['Cluster_Labels', 'Behavior'])\n",
    "complete_cluster_behavior_stats = pd.merge(complete_cluster_behavior_stats, cluster_behavior_stats, on=['Cluster_Labels', 'Behavior'], how='left').fillna(0)\n",
    "\n",
    "complete_cluster_behavior_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # 결측값 제거 및 수치형 변수 선택\n",
    "# data_clean = data.dropna()\n",
    "# numeric_data = data_clean[numeric_columns]\n",
    "\n",
    "# # 데이터 정규화\n",
    "# scaler = StandardScaler()\n",
    "# scaled_data = scaler.fit_transform(numeric_data)\n",
    "\n",
    "# # 정규화된 데이터 프레임 생성\n",
    "# scaled_df = pd.DataFrame(scaled_data, columns=numeric_columns)\n",
    "\n",
    "# scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_selected.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster_Labels'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_judgment(value):\n",
    "    if value < 1:\n",
    "        return 'Decrease'\n",
    "    else:\n",
    "        return 'Increase'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "df['가치판단'] = df['토빈스큐_기업가치'].apply(value_judgment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>업종코드</th>\n",
       "      <th>Market</th>\n",
       "      <th>자산총계(요약)(백만원)</th>\n",
       "      <th>부채총계(요약)(백만원)</th>\n",
       "      <th>자본총계(요약)(백만원)</th>\n",
       "      <th>당기순이익(요약)(백만원)</th>\n",
       "      <th>ROE(자기자본이익률)</th>\n",
       "      <th>발행주식수(*)(연결)(주)</th>\n",
       "      <th>...</th>\n",
       "      <th>주식수_처분</th>\n",
       "      <th>기업규모_0.0</th>\n",
       "      <th>기업규모_10.0</th>\n",
       "      <th>기업규모_20.0</th>\n",
       "      <th>기업규모_30.0</th>\n",
       "      <th>기업규모_90.0</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>토빈스큐_기업가치</th>\n",
       "      <th>Cluster_Labels</th>\n",
       "      <th>가치판단</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140674</td>\n",
       "      <td>-0.106036</td>\n",
       "      <td>-0.143391</td>\n",
       "      <td>-0.087043</td>\n",
       "      <td>-1.480690</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140368</td>\n",
       "      <td>-0.105754</td>\n",
       "      <td>-0.143181</td>\n",
       "      <td>-0.084630</td>\n",
       "      <td>-0.623225</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140196</td>\n",
       "      <td>-0.105992</td>\n",
       "      <td>-0.142291</td>\n",
       "      <td>-0.086195</td>\n",
       "      <td>-0.684068</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.139011</td>\n",
       "      <td>-0.106193</td>\n",
       "      <td>-0.138955</td>\n",
       "      <td>-0.081569</td>\n",
       "      <td>-0.098422</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000048</td>\n",
       "      <td>0</td>\n",
       "      <td>Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137782</td>\n",
       "      <td>-0.105132</td>\n",
       "      <td>-0.137965</td>\n",
       "      <td>-0.088486</td>\n",
       "      <td>-0.283052</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30812</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>-0.015026</td>\n",
       "      <td>-0.130146</td>\n",
       "      <td>-0.257867</td>\n",
       "      <td>-0.261632</td>\n",
       "      <td>1.377484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.103140</td>\n",
       "      <td>-0.059955</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>-0.176378</td>\n",
       "      <td>-0.285255</td>\n",
       "      <td>0.787190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30814</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.113157</td>\n",
       "      <td>-0.068005</td>\n",
       "      <td>-0.148946</td>\n",
       "      <td>-0.148569</td>\n",
       "      <td>-0.276229</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30815</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.116777</td>\n",
       "      <td>-0.088773</td>\n",
       "      <td>-0.117575</td>\n",
       "      <td>-0.050994</td>\n",
       "      <td>0.104588</td>\n",
       "      <td>1.979397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30816</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.112347</td>\n",
       "      <td>-0.085611</td>\n",
       "      <td>-0.112715</td>\n",
       "      <td>-0.054349</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>1.979397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296076</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Long-term Holding</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30801 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            회사명  거래소코드  업종코드  Market  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
       "0      (주)CMG제약  58820     1       0      -0.140674      -0.106036   \n",
       "1      (주)CMG제약  58820     1       0      -0.140368      -0.105754   \n",
       "2      (주)CMG제약  58820     1       0      -0.140196      -0.105992   \n",
       "3      (주)CMG제약  58820     1       0      -0.139011      -0.106193   \n",
       "4      (주)CMG제약  58820     1       0      -0.137782      -0.105132   \n",
       "...         ...    ...   ...     ...            ...            ...   \n",
       "30812   흥아해운(주)   3280     1       1      -0.064143      -0.015026   \n",
       "30813   흥아해운(주)   3280     1       1      -0.103140      -0.059955   \n",
       "30814   흥아해운(주)   3280     1       1      -0.113157      -0.068005   \n",
       "30815   흥아해운(주)   3280     1       1      -0.116777      -0.088773   \n",
       "30816   흥아해운(주)   3280     1       1      -0.112347      -0.085611   \n",
       "\n",
       "       자본총계(요약)(백만원)  당기순이익(요약)(백만원)  ROE(자기자본이익률)  발행주식수(*)(연결)(주)  ...  \\\n",
       "0          -0.143391       -0.087043     -1.480690        -0.254495  ...   \n",
       "1          -0.143181       -0.084630     -0.623225        -0.254495  ...   \n",
       "2          -0.142291       -0.086195     -0.684068        -0.254495  ...   \n",
       "3          -0.138955       -0.081569     -0.098422        -0.254495  ...   \n",
       "4          -0.137965       -0.088486     -0.283052        -0.254495  ...   \n",
       "...              ...             ...           ...              ...  ...   \n",
       "30812      -0.130146       -0.257867     -0.261632         1.377484  ...   \n",
       "30813      -0.139706       -0.176378     -0.285255         0.787190  ...   \n",
       "30814      -0.148946       -0.148569     -0.276229         0.830118  ...   \n",
       "30815      -0.117575       -0.050994      0.104588         1.979397  ...   \n",
       "30816      -0.112715       -0.054349      0.073314         1.979397  ...   \n",
       "\n",
       "         주식수_처분  기업규모_0.0  기업규모_10.0  기업규모_20.0  기업규모_30.0  기업규모_90.0  \\\n",
       "0     -0.296076         0          0          1          0          0   \n",
       "1     -0.296076         0          0          1          0          0   \n",
       "2     -0.296076         0          0          1          0          0   \n",
       "3     -0.296076         0          0          1          0          0   \n",
       "4     -0.296076         0          0          1          0          0   \n",
       "...         ...       ...        ...        ...        ...        ...   \n",
       "30812 -0.296076         0          0          0          1          0   \n",
       "30813 -0.296076         0          0          0          1          0   \n",
       "30814 -0.296076         0          0          0          1          0   \n",
       "30815 -0.296076         0          0          0          1          0   \n",
       "30816 -0.296076         0          1          0          0          0   \n",
       "\n",
       "                Behavior  토빈스큐_기업가치  Cluster_Labels      가치판단  \n",
       "0      Long-term Holding   1.000000               0  Decrease  \n",
       "1      Long-term Holding   1.000000               0  Decrease  \n",
       "2      Long-term Holding   1.000000               0  Decrease  \n",
       "3      Long-term Holding   1.000048               0  Increase  \n",
       "4      Long-term Holding   1.000000               0  Decrease  \n",
       "...                  ...        ...             ...       ...  \n",
       "30812  Long-term Holding   1.000000               2  Decrease  \n",
       "30813  Long-term Holding   1.000000               2  Decrease  \n",
       "30814  Long-term Holding   1.000050               2  Increase  \n",
       "30815  Long-term Holding   1.000000               2  Decrease  \n",
       "30816  Long-term Holding   1.000000               2  Decrease  \n",
       "\n",
       "[30801 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_dummies = pd.get_dummies(df['Behavior'], prefix='Behavior')\n",
    "df = pd.concat([df, behavior_dummies], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_dummies = pd.get_dummies(df['Cluster_Labels'], prefix='Cluster_Label')\n",
    "\n",
    "# 원핫 인코딩된 데이터프레임을 원본 데이터프레임에 결합\n",
    "df = pd.concat([df, cluster_labels_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>업종코드</th>\n",
       "      <th>Market</th>\n",
       "      <th>자산총계(요약)(백만원)</th>\n",
       "      <th>부채총계(요약)(백만원)</th>\n",
       "      <th>자본총계(요약)(백만원)</th>\n",
       "      <th>당기순이익(요약)(백만원)</th>\n",
       "      <th>ROE(자기자본이익률)</th>\n",
       "      <th>발행주식수(*)(연결)(주)</th>\n",
       "      <th>...</th>\n",
       "      <th>토빈스큐_기업가치</th>\n",
       "      <th>Cluster_Labels</th>\n",
       "      <th>가치판단</th>\n",
       "      <th>Behavior_Burned</th>\n",
       "      <th>Behavior_Disposed_Faster</th>\n",
       "      <th>Behavior_Disposed_Slower</th>\n",
       "      <th>Behavior_Long-term Holding</th>\n",
       "      <th>Cluster_Label_0</th>\n",
       "      <th>Cluster_Label_1</th>\n",
       "      <th>Cluster_Label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140674</td>\n",
       "      <td>-0.106036</td>\n",
       "      <td>-0.143391</td>\n",
       "      <td>-0.087043</td>\n",
       "      <td>-1.480690</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140368</td>\n",
       "      <td>-0.105754</td>\n",
       "      <td>-0.143181</td>\n",
       "      <td>-0.084630</td>\n",
       "      <td>-0.623225</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140196</td>\n",
       "      <td>-0.105992</td>\n",
       "      <td>-0.142291</td>\n",
       "      <td>-0.086195</td>\n",
       "      <td>-0.684068</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.139011</td>\n",
       "      <td>-0.106193</td>\n",
       "      <td>-0.138955</td>\n",
       "      <td>-0.081569</td>\n",
       "      <td>-0.098422</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000048</td>\n",
       "      <td>0</td>\n",
       "      <td>Increase</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137782</td>\n",
       "      <td>-0.105132</td>\n",
       "      <td>-0.137965</td>\n",
       "      <td>-0.088486</td>\n",
       "      <td>-0.283052</td>\n",
       "      <td>-0.254495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30812</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.064143</td>\n",
       "      <td>-0.015026</td>\n",
       "      <td>-0.130146</td>\n",
       "      <td>-0.257867</td>\n",
       "      <td>-0.261632</td>\n",
       "      <td>1.377484</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.103140</td>\n",
       "      <td>-0.059955</td>\n",
       "      <td>-0.139706</td>\n",
       "      <td>-0.176378</td>\n",
       "      <td>-0.285255</td>\n",
       "      <td>0.787190</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30814</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.113157</td>\n",
       "      <td>-0.068005</td>\n",
       "      <td>-0.148946</td>\n",
       "      <td>-0.148569</td>\n",
       "      <td>-0.276229</td>\n",
       "      <td>0.830118</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000050</td>\n",
       "      <td>2</td>\n",
       "      <td>Increase</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30815</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.116777</td>\n",
       "      <td>-0.088773</td>\n",
       "      <td>-0.117575</td>\n",
       "      <td>-0.050994</td>\n",
       "      <td>0.104588</td>\n",
       "      <td>1.979397</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30816</th>\n",
       "      <td>흥아해운(주)</td>\n",
       "      <td>3280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.112347</td>\n",
       "      <td>-0.085611</td>\n",
       "      <td>-0.112715</td>\n",
       "      <td>-0.054349</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>1.979397</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Decrease</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30801 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            회사명  거래소코드  업종코드  Market  자산총계(요약)(백만원)  부채총계(요약)(백만원)  \\\n",
       "0      (주)CMG제약  58820     1       0      -0.140674      -0.106036   \n",
       "1      (주)CMG제약  58820     1       0      -0.140368      -0.105754   \n",
       "2      (주)CMG제약  58820     1       0      -0.140196      -0.105992   \n",
       "3      (주)CMG제약  58820     1       0      -0.139011      -0.106193   \n",
       "4      (주)CMG제약  58820     1       0      -0.137782      -0.105132   \n",
       "...         ...    ...   ...     ...            ...            ...   \n",
       "30812   흥아해운(주)   3280     1       1      -0.064143      -0.015026   \n",
       "30813   흥아해운(주)   3280     1       1      -0.103140      -0.059955   \n",
       "30814   흥아해운(주)   3280     1       1      -0.113157      -0.068005   \n",
       "30815   흥아해운(주)   3280     1       1      -0.116777      -0.088773   \n",
       "30816   흥아해운(주)   3280     1       1      -0.112347      -0.085611   \n",
       "\n",
       "       자본총계(요약)(백만원)  당기순이익(요약)(백만원)  ROE(자기자본이익률)  발행주식수(*)(연결)(주)  ...  \\\n",
       "0          -0.143391       -0.087043     -1.480690        -0.254495  ...   \n",
       "1          -0.143181       -0.084630     -0.623225        -0.254495  ...   \n",
       "2          -0.142291       -0.086195     -0.684068        -0.254495  ...   \n",
       "3          -0.138955       -0.081569     -0.098422        -0.254495  ...   \n",
       "4          -0.137965       -0.088486     -0.283052        -0.254495  ...   \n",
       "...              ...             ...           ...              ...  ...   \n",
       "30812      -0.130146       -0.257867     -0.261632         1.377484  ...   \n",
       "30813      -0.139706       -0.176378     -0.285255         0.787190  ...   \n",
       "30814      -0.148946       -0.148569     -0.276229         0.830118  ...   \n",
       "30815      -0.117575       -0.050994      0.104588         1.979397  ...   \n",
       "30816      -0.112715       -0.054349      0.073314         1.979397  ...   \n",
       "\n",
       "       토빈스큐_기업가치  Cluster_Labels      가치판단  Behavior_Burned  \\\n",
       "0       1.000000               0  Decrease                0   \n",
       "1       1.000000               0  Decrease                0   \n",
       "2       1.000000               0  Decrease                0   \n",
       "3       1.000048               0  Increase                0   \n",
       "4       1.000000               0  Decrease                0   \n",
       "...          ...             ...       ...              ...   \n",
       "30812   1.000000               2  Decrease                0   \n",
       "30813   1.000000               2  Decrease                0   \n",
       "30814   1.000050               2  Increase                0   \n",
       "30815   1.000000               2  Decrease                0   \n",
       "30816   1.000000               2  Decrease                0   \n",
       "\n",
       "       Behavior_Disposed_Faster  Behavior_Disposed_Slower  \\\n",
       "0                             0                         0   \n",
       "1                             0                         0   \n",
       "2                             0                         0   \n",
       "3                             0                         0   \n",
       "4                             0                         0   \n",
       "...                         ...                       ...   \n",
       "30812                         0                         0   \n",
       "30813                         0                         0   \n",
       "30814                         0                         0   \n",
       "30815                         0                         0   \n",
       "30816                         0                         0   \n",
       "\n",
       "       Behavior_Long-term Holding  Cluster_Label_0  Cluster_Label_1  \\\n",
       "0                               1                1                0   \n",
       "1                               1                1                0   \n",
       "2                               1                1                0   \n",
       "3                               1                1                0   \n",
       "4                               1                1                0   \n",
       "...                           ...              ...              ...   \n",
       "30812                           1                0                0   \n",
       "30813                           1                0                0   \n",
       "30814                           1                0                0   \n",
       "30815                           1                0                0   \n",
       "30816                           1                0                0   \n",
       "\n",
       "       Cluster_Label_2  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "30812                1  \n",
       "30813                1  \n",
       "30814                1  \n",
       "30815                1  \n",
       "30816                1  \n",
       "\n",
       "[30801 rows x 31 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/3433941676.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/3433941676.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/3433941676.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/3433941676.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Feature_Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.865274</td>\n",
       "      <td>[-0.0821080494724368, 0.029766200044296223, 0....</td>\n",
       "      <td>Index(['Behavior_Burned', 'Behavior_Disposed_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.865707</td>\n",
       "      <td>[0.44904667, 0.035448365, 0.02228397, 0.000118...</td>\n",
       "      <td>Index(['Behavior_Burned', 'Behavior_Disposed_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.865707</td>\n",
       "      <td>[0.3714293865393703, 0.01685175662822167, 0.00...</td>\n",
       "      <td>Index(['Behavior_Burned', 'Behavior_Disposed_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.865707</td>\n",
       "      <td>[0.1644257009238856, 0.07091385969250602, 0.03...</td>\n",
       "      <td>Index(['Behavior_Burned', 'Behavior_Disposed_F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  \\\n",
       "0  Logistic Regression  0.865274   \n",
       "1              XGBoost  0.865707   \n",
       "2    Gradient Boosting  0.865707   \n",
       "3        Random Forest  0.865707   \n",
       "\n",
       "                                  Feature_Importance  \\\n",
       "0  [-0.0821080494724368, 0.029766200044296223, 0....   \n",
       "1  [0.44904667, 0.035448365, 0.02228397, 0.000118...   \n",
       "2  [0.3714293865393703, 0.01685175662822167, 0.00...   \n",
       "3  [0.1644257009238856, 0.07091385969250602, 0.03...   \n",
       "\n",
       "                                             Feature  \n",
       "0  Index(['Behavior_Burned', 'Behavior_Disposed_F...  \n",
       "1  Index(['Behavior_Burned', 'Behavior_Disposed_F...  \n",
       "2  Index(['Behavior_Burned', 'Behavior_Disposed_F...  \n",
       "3  Index(['Behavior_Burned', 'Behavior_Disposed_F...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 가치 판단 라벨을 숫자로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\",\t\"Behavior_Disposed_Faster\",\t\"Behavior_Disposed_Slower\",\t\"Behavior_Long-term Holding\",'Cluster_Label_0',\t'Cluster_Label_1',\t'Cluster_Label_2'\n",
    "] \n",
    "\n",
    "\n",
    "\n",
    "# 결과를 저장할 데이터 프레임 초기화\n",
    "results_df = pd.DataFrame(columns=[ 'Model', 'Accuracy', 'Feature_Importance'])\n",
    "\n",
    "# 각 Behavior 카테고리별로 반복\n",
    "\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "    \n",
    "    # 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    # 모델 정의\n",
    "models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=0),\n",
    "        'XGBoost': XGBClassifier(random_state=0),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "        'Random Forest': RandomForestClassifier(random_state=0)\n",
    "    }\n",
    "    \n",
    "    # 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # 피쳐 중요도 추출 (로지스틱 회귀는 coef_ 사용)\n",
    "        if model_name == 'Logistic Regression':\n",
    "            feature_importance = model.coef_[0]\n",
    "        else:\n",
    "            feature_importance = model.feature_importances_\n",
    "        \n",
    "        # 피처 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "        feature_importances_df = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'Model': model_name,\n",
    "            'Feature_Importance': feature_importance\n",
    "        })\n",
    "        \n",
    "        # 결과 저장\n",
    "        results_df = results_df.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Feature': X_train.columns,\n",
    "            'Feature_Importance': feature_importance\n",
    "        }, ignore_index=True)    \n",
    "        \n",
    "# 결과 출력\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Feature Importances:\n",
      "                      Feature  Importance\n",
      "0             Cluster_Label_1    0.958912\n",
      "1    Behavior_Disposed_Slower    0.030311\n",
      "2    Behavior_Disposed_Faster    0.029766\n",
      "3  Behavior_Long-term Holding    0.020543\n",
      "4             Behavior_Burned   -0.082108\n",
      "5             Cluster_Label_0   -0.462736\n",
      "6             Cluster_Label_2   -0.497664\n",
      "\n",
      "\n",
      "XGBoost Feature Importances:\n",
      "                      Feature  Importance\n",
      "0             Cluster_Label_1    0.475736\n",
      "1             Behavior_Burned    0.449047\n",
      "2    Behavior_Disposed_Faster    0.035448\n",
      "3    Behavior_Disposed_Slower    0.022284\n",
      "4             Cluster_Label_0    0.017366\n",
      "5  Behavior_Long-term Holding    0.000119\n",
      "6             Cluster_Label_2    0.000000\n",
      "\n",
      "\n",
      "Gradient Boosting Feature Importances:\n",
      "                      Feature  Importance\n",
      "0             Cluster_Label_1    0.543462\n",
      "1             Behavior_Burned    0.371429\n",
      "2             Cluster_Label_0    0.028609\n",
      "3             Cluster_Label_2    0.024189\n",
      "4    Behavior_Disposed_Faster    0.016852\n",
      "5  Behavior_Long-term Holding    0.011506\n",
      "6    Behavior_Disposed_Slower    0.003953\n",
      "\n",
      "\n",
      "Random Forest Feature Importances:\n",
      "                      Feature  Importance\n",
      "0             Cluster_Label_1    0.404763\n",
      "1             Behavior_Burned    0.164426\n",
      "2             Cluster_Label_0    0.162346\n",
      "3             Cluster_Label_2    0.108637\n",
      "4    Behavior_Disposed_Faster    0.070914\n",
      "5  Behavior_Long-term Holding    0.056576\n",
      "6    Behavior_Disposed_Slower    0.032339\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 가정: `df`는 이미 준비된 데이터프레임이고, 필요한 열 변환 작업이 완료되었다고 가정합니다.\n",
    "\n",
    "# 필요한 라이브러리와 모듈을 임포트합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "# 선택된 특성 목록\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\",\n",
    "    'Cluster_Label_0', 'Cluster_Label_1', 'Cluster_Label_2'\n",
    "]\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0),\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "feature_importances_dfs = {}\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 피쳐 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # 각 모델별로 특성 중요도 데이터프레임을 저장\n",
    "    feature_importances_dfs[model_name] = feature_importances_df\n",
    "\n",
    "# 각 모델별 특성 중요도를 출력\n",
    "for model_name, fi_df in feature_importances_dfs.items():\n",
    "    print(f\"{model_name} Feature Importances:\")\n",
    "    print(fi_df)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>0.958912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>0.543462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>0.475736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>0.449047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>0.404763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>0.164426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>0.162346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>0.108637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.070914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.056576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.035448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.032339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.030311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.029766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>0.028609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>0.024189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.022284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.020543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>0.017366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.016852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.011506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.003953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>-0.082108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>-0.462736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>-0.497664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                     Feature  Importance\n",
       "5  Logistic Regression             Cluster_Label_1    0.958912\n",
       "5    Gradient Boosting             Cluster_Label_1    0.543462\n",
       "5              XGBoost             Cluster_Label_1    0.475736\n",
       "0              XGBoost             Behavior_Burned    0.449047\n",
       "5        Random Forest             Cluster_Label_1    0.404763\n",
       "0    Gradient Boosting             Behavior_Burned    0.371429\n",
       "0        Random Forest             Behavior_Burned    0.164426\n",
       "4        Random Forest             Cluster_Label_0    0.162346\n",
       "6        Random Forest             Cluster_Label_2    0.108637\n",
       "1        Random Forest    Behavior_Disposed_Faster    0.070914\n",
       "3        Random Forest  Behavior_Long-term Holding    0.056576\n",
       "1              XGBoost    Behavior_Disposed_Faster    0.035448\n",
       "2        Random Forest    Behavior_Disposed_Slower    0.032339\n",
       "2  Logistic Regression    Behavior_Disposed_Slower    0.030311\n",
       "1  Logistic Regression    Behavior_Disposed_Faster    0.029766\n",
       "4    Gradient Boosting             Cluster_Label_0    0.028609\n",
       "6    Gradient Boosting             Cluster_Label_2    0.024189\n",
       "2              XGBoost    Behavior_Disposed_Slower    0.022284\n",
       "3  Logistic Regression  Behavior_Long-term Holding    0.020543\n",
       "4              XGBoost             Cluster_Label_0    0.017366\n",
       "1    Gradient Boosting    Behavior_Disposed_Faster    0.016852\n",
       "3    Gradient Boosting  Behavior_Long-term Holding    0.011506\n",
       "2    Gradient Boosting    Behavior_Disposed_Slower    0.003953\n",
       "3              XGBoost  Behavior_Long-term Holding    0.000119\n",
       "6              XGBoost             Cluster_Label_2    0.000000\n",
       "0  Logistic Regression             Behavior_Burned   -0.082108\n",
       "4  Logistic Regression             Cluster_Label_0   -0.462736\n",
       "6  Logistic Regression             Cluster_Label_2   -0.497664"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리와 모듈을 임포트합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "# 선택된 특성 목록\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\",\n",
    "    'Cluster_Label_0', 'Cluster_Label_1', 'Cluster_Label_2'\n",
    "]\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0),\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "all_feature_importances_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 피쳐 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "\n",
    "    # 모든 모델의 특성 중요도를 하나의 데이터프레임에 추가\n",
    "    all_feature_importances_df = pd.concat([all_feature_importances_df, feature_importances_df], axis=0)\n",
    "\n",
    "# 피처 중요도를 'Importance'에 따라 내림차순으로 정렬\n",
    "all_feature_importances_df = all_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "all_feature_importances_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기가주요한부분 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model                     Feature  Importance\n",
      "0    Gradient Boosting             Behavior_Burned    0.881325\n",
      "2  Logistic Regression    Behavior_Disposed_Slower    0.774168\n",
      "0        Random Forest             Behavior_Burned    0.768458\n",
      "0              XGBoost             Behavior_Burned    0.668004\n",
      "3  Logistic Regression  Behavior_Long-term Holding    0.570801\n",
      "3        Random Forest  Behavior_Long-term Holding    0.137497\n",
      "3              XGBoost  Behavior_Long-term Holding    0.133349\n",
      "1              XGBoost    Behavior_Disposed_Faster    0.122037\n",
      "2              XGBoost    Behavior_Disposed_Slower    0.076610\n",
      "3    Gradient Boosting  Behavior_Long-term Holding    0.056750\n",
      "2    Gradient Boosting    Behavior_Disposed_Slower    0.051928\n",
      "1        Random Forest    Behavior_Disposed_Faster    0.051056\n",
      "2        Random Forest    Behavior_Disposed_Slower    0.042990\n",
      "1    Gradient Boosting    Behavior_Disposed_Faster    0.009997\n",
      "1  Logistic Regression    Behavior_Disposed_Faster   -0.222442\n",
      "0  Logistic Regression             Behavior_Burned   -1.122407\n"
     ]
    }
   ],
   "source": [
    "# 클러스터 라벨을 종속 변수로 사용\n",
    "y = df['Cluster_Labels']  # 예를 들어 df['Cluster_Labels']가 클러스터 라벨을 포함하는 열이라고 가정합니다.\n",
    "\n",
    "# 선택된 특성 목록에서 클러스터 라벨 관련 특성을 제거\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\"\n",
    "]\n",
    "\n",
    "# 클러스터 라벨을 예측하는 데 사용할 특성 세트\n",
    "X = df[selected_columns]\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0, max_iter=1000),  # 로지스틱 회귀가 수렴하기 위해 max_iter를 증가시킬 수 있음\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "all_feature_importances_df = pd.DataFrame()\n",
    "predictions = {}\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    predictions[model_name] = y_pred\n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 피쳐 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "\n",
    "    # 모든 모델의 특성 중요도를 하나의 데이터프레임에 추가\n",
    "    all_feature_importances_df = pd.concat([all_feature_importances_df, feature_importances_df], axis=0)\n",
    "\n",
    "# 피처 중요도를 'Importance'에 따라 내림차순으로 정렬\n",
    "all_feature_importances_df = all_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(all_feature_importances_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Value_Judgment_Label  Frequency\n",
      "0  Logistic Regression                     0       8644\n",
      "1  Logistic Regression                     2        597\n",
      "0              XGBoost                     0       8644\n",
      "1              XGBoost                     2        597\n",
      "0    Gradient Boosting                     0       8644\n",
      "1    Gradient Boosting                     2        597\n",
      "0        Random Forest                     0       8644\n",
      "1        Random Forest                     2        597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 빈 데이터프레임을 초기화합니다.\n",
    "frequency_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델별로 예측된 라벨의 빈도를 데이터프레임에 추가합니다.\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # 현재 모델에 대한 빈도수를 계산합니다.\n",
    "    freq_series = pd.Series(y_pred).value_counts().rename_axis('Value_Judgment_Label').reset_index(name='Frequency')\n",
    "    freq_series['Model'] = model_name  # 모델 이름을 추가합니다.\n",
    "    frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
    "\n",
    "# 데이터프레임의 순서를 재배치하여 보기 좋게 만듭니다.\n",
    "frequency_df = frequency_df[['Model', 'Value_Judgment_Label', 'Frequency']]\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(frequency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>6.362244e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>6.277697e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>4.423435e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>2.398886e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>2.190693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>2.026784e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>1.313597e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>1.256858e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>1.048754e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>9.793259e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>9.141700e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>6.174387e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>2.811618e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>1.901154e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Cluster_Label_0</td>\n",
       "      <td>1.875380e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>1.580416e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>7.897769e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>1.216507e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>-5.090501e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                     Feature    Importance\n",
       "4              XGBoost             Cluster_Label_0  6.362244e-01\n",
       "4    Gradient Boosting             Cluster_Label_0  6.277697e-01\n",
       "4        Random Forest             Cluster_Label_0  4.423435e-01\n",
       "1              XGBoost    Behavior_Disposed_Faster  2.398886e-01\n",
       "1    Gradient Boosting    Behavior_Disposed_Faster  2.190693e-01\n",
       "0        Random Forest             Behavior_Burned  2.026784e-01\n",
       "1        Random Forest    Behavior_Disposed_Faster  1.313597e-01\n",
       "2        Random Forest    Behavior_Disposed_Slower  1.256858e-01\n",
       "0              XGBoost             Behavior_Burned  1.048754e-01\n",
       "3        Random Forest  Behavior_Long-term Holding  9.793259e-02\n",
       "0    Gradient Boosting             Behavior_Burned  9.141700e-02\n",
       "2    Gradient Boosting    Behavior_Disposed_Slower  6.174387e-02\n",
       "1  Logistic Regression    Behavior_Disposed_Faster  2.811618e-02\n",
       "2              XGBoost    Behavior_Disposed_Slower  1.901154e-02\n",
       "4  Logistic Regression             Cluster_Label_0  1.875380e-02\n",
       "2  Logistic Regression    Behavior_Disposed_Slower  1.580416e-02\n",
       "3  Logistic Regression  Behavior_Long-term Holding  7.897769e-03\n",
       "3    Gradient Boosting  Behavior_Long-term Holding  1.216507e-07\n",
       "3              XGBoost  Behavior_Long-term Holding  0.000000e+00\n",
       "0  Logistic Regression             Behavior_Burned -5.090501e-02"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리와 모듈을 임포트합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "# 선택된 특성 목록\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\",\n",
    "    'Cluster_Label_0'\n",
    "]\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0),\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "all_feature_importances_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 피쳐 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "\n",
    "    # 모든 모델의 특성 중요도를 하나의 데이터프레임에 추가\n",
    "    all_feature_importances_df = pd.concat([all_feature_importances_df, feature_importances_df], axis=0)\n",
    "\n",
    "# 피처 중요도를 'Importance'에 따라 내림차순으로 정렬\n",
    "all_feature_importances_df = all_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "all_feature_importances_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>1.405571e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>7.073424e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>5.762155e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Cluster_Label_1</td>\n",
       "      <td>4.960204e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>4.720416e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>3.940541e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>1.440154e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>8.458873e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>4.607238e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>3.186122e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>3.121810e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>3.044464e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>2.307316e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>1.907532e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>1.798114e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>1.065506e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>8.079984e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>6.854132e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>3.337624e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>-8.676833e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                     Feature    Importance\n",
       "4  Logistic Regression             Cluster_Label_1  1.405571e+00\n",
       "4        Random Forest             Cluster_Label_1  7.073424e-01\n",
       "4    Gradient Boosting             Cluster_Label_1  5.762155e-01\n",
       "4              XGBoost             Cluster_Label_1  4.960204e-01\n",
       "0              XGBoost             Behavior_Burned  4.720416e-01\n",
       "0    Gradient Boosting             Behavior_Burned  3.940541e-01\n",
       "0        Random Forest             Behavior_Burned  1.440154e-01\n",
       "1        Random Forest    Behavior_Disposed_Faster  8.458873e-02\n",
       "3        Random Forest  Behavior_Long-term Holding  4.607238e-02\n",
       "1  Logistic Regression    Behavior_Disposed_Faster  3.186122e-02\n",
       "2  Logistic Regression    Behavior_Disposed_Slower  3.121810e-02\n",
       "1              XGBoost    Behavior_Disposed_Faster  3.044464e-02\n",
       "3  Logistic Regression  Behavior_Long-term Holding  2.307316e-02\n",
       "1    Gradient Boosting    Behavior_Disposed_Faster  1.907532e-02\n",
       "2        Random Forest    Behavior_Disposed_Slower  1.798114e-02\n",
       "3    Gradient Boosting  Behavior_Long-term Holding  1.065506e-02\n",
       "3              XGBoost  Behavior_Long-term Holding  8.079984e-04\n",
       "2              XGBoost    Behavior_Disposed_Slower  6.854132e-04\n",
       "2    Gradient Boosting    Behavior_Disposed_Slower  3.337624e-10\n",
       "0  Logistic Regression             Behavior_Burned -8.676833e-02"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리와 모듈을 임포트합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "# 선택된 특성 목록\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\",'Cluster_Label_1'\n",
    "]\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0),\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "all_feature_importances_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 피쳐 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "\n",
    "    # 모든 모델의 특성 중요도를 하나의 데이터프레임에 추가\n",
    "    all_feature_importances_df = pd.concat([all_feature_importances_df, feature_importances_df], axis=0)\n",
    "\n",
    "# 피처 중요도를 'Importance'에 따라 내림차순으로 정렬\n",
    "all_feature_importances_df = all_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "all_feature_importances_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>0.419934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>0.412619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>0.395016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.373308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>0.304052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>0.171130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.163023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.153470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.113791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.099758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.093932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>0.056768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Faster</td>\n",
       "      <td>0.026148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Disposed_Slower</td>\n",
       "      <td>0.014741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.005347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Behavior_Long-term Holding</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Behavior_Burned</td>\n",
       "      <td>-0.047037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Cluster_Label_2</td>\n",
       "      <td>-0.048884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model                     Feature  Importance\n",
       "4    Gradient Boosting             Cluster_Label_2    0.419934\n",
       "4        Random Forest             Cluster_Label_2    0.412619\n",
       "0              XGBoost             Behavior_Burned    0.395016\n",
       "1    Gradient Boosting    Behavior_Disposed_Faster    0.373308\n",
       "4              XGBoost             Cluster_Label_2    0.304052\n",
       "1              XGBoost    Behavior_Disposed_Faster    0.207000\n",
       "0        Random Forest             Behavior_Burned    0.171130\n",
       "2        Random Forest    Behavior_Disposed_Slower    0.163023\n",
       "1        Random Forest    Behavior_Disposed_Faster    0.153470\n",
       "2    Gradient Boosting    Behavior_Disposed_Slower    0.113791\n",
       "3        Random Forest  Behavior_Long-term Holding    0.099758\n",
       "2              XGBoost    Behavior_Disposed_Slower    0.093932\n",
       "0    Gradient Boosting             Behavior_Burned    0.056768\n",
       "3    Gradient Boosting  Behavior_Long-term Holding    0.036200\n",
       "1  Logistic Regression    Behavior_Disposed_Faster    0.026148\n",
       "2  Logistic Regression    Behavior_Disposed_Slower    0.014741\n",
       "3  Logistic Regression  Behavior_Long-term Holding    0.005347\n",
       "3              XGBoost  Behavior_Long-term Holding    0.000000\n",
       "0  Logistic Regression             Behavior_Burned   -0.047037\n",
       "4  Logistic Regression             Cluster_Label_2   -0.048884"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리와 모듈을 임포트합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "# 선택된 특성 목록\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\",'Cluster_Label_2'\n",
    "]\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0),\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "all_feature_importances_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 피쳐 중요도와 열 이름을 매핑한 데이터프레임 생성\n",
    "    feature_importances_df = pd.DataFrame({\n",
    "        'Model': model_name,\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': feature_importance\n",
    "    })\n",
    "\n",
    "    # 모든 모델의 특성 중요도를 하나의 데이터프레임에 추가\n",
    "    all_feature_importances_df = pd.concat([all_feature_importances_df, feature_importances_df], axis=0)\n",
    "\n",
    "# 피처 중요도를 'Importance'에 따라 내림차순으로 정렬\n",
    "all_feature_importances_df = all_feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "all_feature_importances_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/2119786850.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/2119786850.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/2119786850.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/2119786850.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 라벨 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "df['Value_Judgment_Label'] = label_encoder.fit_transform(df['가치판단'])\n",
    "\n",
    "# 선택된 특성 목록\n",
    "selected_columns = [\n",
    "    \"Behavior_Burned\", \"Behavior_Disposed_Faster\", \"Behavior_Disposed_Slower\", \"Behavior_Long-term Holding\",'Cluster_Label_2'\n",
    "]\n",
    "\n",
    "# 특성과 라벨 준비\n",
    "X = df[selected_columns]\n",
    "y = df['Value_Judgment_Label']\n",
    "\n",
    "# 훈련 세트와 테스트 세트 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=0),\n",
    "    'XGBoost': XGBClassifier(random_state=0),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=0),\n",
    "    'Random Forest': RandomForestClassifier(random_state=0)\n",
    "}\n",
    "\n",
    "# 결과를 저장할 데이터프레임 초기화\n",
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Feature_Importance'])\n",
    "predictions = {}\n",
    "\n",
    "# 각 모델별로 훈련 및 성능 측정\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # 예측된 라벨의 빈도를 저장\n",
    "    predictions[model_name] = y_pred\n",
    "    \n",
    "    # 피쳐 중요도 추출\n",
    "    feature_importance = model.coef_[0] if model_name == 'Logistic Regression' else model.feature_importances_\n",
    "    \n",
    "    # 결과 데이터프레임 업데이트\n",
    "    results_df = results_df.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Feature_Importance': feature_importance\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Value_Judgment_Label  Frequency\n",
      "0  Logistic Regression                     0       9241\n",
      "0              XGBoost                     0       9233\n",
      "1              XGBoost                     1          8\n",
      "0    Gradient Boosting                     0       9233\n",
      "1    Gradient Boosting                     1          8\n",
      "0        Random Forest                     0       9233\n",
      "1        Random Forest                     1          8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_27454/1380987501.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 빈 데이터프레임을 초기화합니다.\n",
    "frequency_df = pd.DataFrame()\n",
    "\n",
    "# 각 모델별로 예측된 라벨의 빈도를 데이터프레임에 추가합니다.\n",
    "for model_name, y_pred in predictions.items():\n",
    "    # 현재 모델에 대한 빈도수를 계산합니다.\n",
    "    freq_series = pd.Series(y_pred).value_counts().rename_axis('Value_Judgment_Label').reset_index(name='Frequency')\n",
    "    freq_series['Model'] = model_name  # 모델 이름을 추가합니다.\n",
    "    frequency_df = frequency_df.append(freq_series)  # 데이터프레임에 추가합니다.\n",
    "\n",
    "# 데이터프레임의 순서를 재배치하여 보기 좋게 만듭니다.\n",
    "frequency_df = frequency_df[['Model', 'Value_Judgment_Label', 'Frequency']]\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(frequency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    26700\n",
      "1     4101\n",
      "Name: Value_Judgment_Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 종속 변수의 빈도 수 계산\n",
    "value_judgment_frequencies = df['Value_Judgment_Label'].value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "print(value_judgment_frequencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior: Long-term Holding, Model: Logistic Regression\n",
      "0    3537\n",
      "1       2\n",
      "dtype: int64\n",
      "Behavior: Long-term Holding, Model: XGBoost\n",
      "0    3500\n",
      "1      39\n",
      "dtype: int64\n",
      "Behavior: Long-term Holding, Model: Gradient Boosting\n",
      "0    3523\n",
      "1      16\n",
      "dtype: int64\n",
      "Behavior: Long-term Holding, Model: Random Forest\n",
      "0    3512\n",
      "1      27\n",
      "dtype: int64\n",
      "Behavior: Disposed_Slower, Model: Logistic Regression\n",
      "0    2564\n",
      "1       1\n",
      "dtype: int64\n",
      "Behavior: Disposed_Slower, Model: XGBoost\n",
      "0    2522\n",
      "1      43\n",
      "dtype: int64\n",
      "Behavior: Disposed_Slower, Model: Gradient Boosting\n",
      "0    2549\n",
      "1      16\n",
      "dtype: int64\n",
      "Behavior: Disposed_Slower, Model: Random Forest\n",
      "0    2538\n",
      "1      27\n",
      "dtype: int64\n",
      "Behavior: Disposed_Faster, Model: Logistic Regression\n",
      "0    2554\n",
      "1       2\n",
      "dtype: int64\n",
      "Behavior: Disposed_Faster, Model: XGBoost\n",
      "0    2502\n",
      "1      54\n",
      "dtype: int64\n",
      "Behavior: Disposed_Faster, Model: Gradient Boosting\n",
      "0    2539\n",
      "1      17\n",
      "dtype: int64\n",
      "Behavior: Disposed_Faster, Model: Random Forest\n",
      "0    2525\n",
      "1      31\n",
      "dtype: int64\n",
      "Behavior: Burned, Model: Logistic Regression\n",
      "0    571\n",
      "1     12\n",
      "dtype: int64\n",
      "Behavior: Burned, Model: XGBoost\n",
      "0    534\n",
      "1     49\n",
      "dtype: int64\n",
      "Behavior: Burned, Model: Gradient Boosting\n",
      "0    547\n",
      "1     36\n",
      "dtype: int64\n",
      "Behavior: Burned, Model: Random Forest\n",
      "0    536\n",
      "1     47\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 예측 결과를 저장할 딕셔너리 초기화\n",
    "predictions = {}\n",
    "\n",
    "# 각 Behavior 카테고리별로 예측 수행 및 결과 저장\n",
    "for behavior in df['Behavior'].unique():\n",
    "    # 해당 Behavior에 대한 데이터만 추출\n",
    "    subset = df[df['Behavior'] == behavior]\n",
    "    X = subset[selected_columns]\n",
    "    y = subset['Value_Judgment_Label']\n",
    "    \n",
    "    # 훈련 세트와 테스트 세트 분리\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    # 각 모델별로 예측 수행\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 예측 결과를 (Behavior, Model) 키로 사용하여 저장\n",
    "        predictions[(behavior, model_name)] = y_pred\n",
    "\n",
    "# 이제 predictions 딕셔너리를 사용하여 각 Behavior와 모델별로 빈도 계산\n",
    "frequency_results = {}\n",
    "for (behavior, model_name), y_pred in predictions.items():\n",
    "    frequency_results[(behavior, model_name)] = pd.Series(y_pred).value_counts()\n",
    "\n",
    "# 결과 출력\n",
    "for key, value in frequency_results.items():\n",
    "    print(f\"Behavior: {key[0]}, Model: {key[1]}\")\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Behavior                Model  Value_Judgment_Label  Frequency\n",
      "0  Long-term Holding  Logistic Regression                     0       3537\n",
      "1  Long-term Holding  Logistic Regression                     1          2\n",
      "0  Long-term Holding              XGBoost                     0       3500\n",
      "1  Long-term Holding              XGBoost                     1         39\n",
      "0  Long-term Holding    Gradient Boosting                     0       3523\n",
      "1  Long-term Holding    Gradient Boosting                     1         16\n",
      "0  Long-term Holding        Random Forest                     0       3512\n",
      "1  Long-term Holding        Random Forest                     1         27\n",
      "0    Disposed_Slower  Logistic Regression                     0       2564\n",
      "1    Disposed_Slower  Logistic Regression                     1          1\n",
      "0    Disposed_Slower              XGBoost                     0       2522\n",
      "1    Disposed_Slower              XGBoost                     1         43\n",
      "0    Disposed_Slower    Gradient Boosting                     0       2549\n",
      "1    Disposed_Slower    Gradient Boosting                     1         16\n",
      "0    Disposed_Slower        Random Forest                     0       2538\n",
      "1    Disposed_Slower        Random Forest                     1         27\n",
      "0    Disposed_Faster  Logistic Regression                     0       2554\n",
      "1    Disposed_Faster  Logistic Regression                     1          2\n",
      "0    Disposed_Faster              XGBoost                     0       2502\n",
      "1    Disposed_Faster              XGBoost                     1         54\n",
      "0    Disposed_Faster    Gradient Boosting                     0       2539\n",
      "1    Disposed_Faster    Gradient Boosting                     1         17\n",
      "0    Disposed_Faster        Random Forest                     0       2525\n",
      "1    Disposed_Faster        Random Forest                     1         31\n",
      "0             Burned  Logistic Regression                     0        571\n",
      "1             Burned  Logistic Regression                     1         12\n",
      "0             Burned              XGBoost                     0        534\n",
      "1             Burned              XGBoost                     1         49\n",
      "0             Burned    Gradient Boosting                     0        547\n",
      "1             Burned    Gradient Boosting                     1         36\n",
      "0             Burned        Random Forest                     0        536\n",
      "1             Burned        Random Forest                     1         47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n",
      "/var/folders/vm/qw01phdd0gvfvb6qnb3_bk680000gn/T/ipykernel_32390/1070271691.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  frequency_df = frequency_df.append(freq_series)\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 빈 데이터프레임을 초기화합니다.\n",
    "frequency_df = pd.DataFrame()\n",
    "\n",
    "# 각 Behavior와 모델별로 예측된 라벨의 빈도를 데이터프레임에 추가합니다.\n",
    "for (behavior, model_name), y_pred in predictions.items():\n",
    "    # 현재 behavior와 model에 대한 빈도수를 계산합니다.\n",
    "    freq_series = pd.Series(y_pred).value_counts().rename_axis('Value_Judgment_Label').reset_index(name='Frequency')\n",
    "    \n",
    "    # Behavior와 Model 이름을 추가합니다.\n",
    "    freq_series['Behavior'] = behavior\n",
    "    freq_series['Model'] = model_name\n",
    "    \n",
    "    # 이 데이터프레임을 큰 데이터프레임에 추가합니다.\n",
    "    frequency_df = frequency_df.append(freq_series)\n",
    "\n",
    "# 데이터프레임의 순서를 재배치하여 보기 좋게 만듭니다.\n",
    "frequency_df = frequency_df[['Behavior', 'Model', 'Value_Judgment_Label', 'Frequency']]\n",
    "\n",
    "# 결과를 출력합니다.\n",
    "print(frequency_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency_df.to_csv('label_freq.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자본총계(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>부채총계(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.167988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자산총계(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.167529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>당기순이익(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.156831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROE(자기자본이익률)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.155033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>주식수_취득</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.080213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>주식수_처분</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.066407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature          Model  Feature_Importance\n",
       "2   자본총계(요약)(백만원)  Random Forest            0.206000\n",
       "1   부채총계(요약)(백만원)  Random Forest            0.167988\n",
       "0   자산총계(요약)(백만원)  Random Forest            0.167529\n",
       "3  당기순이익(요약)(백만원)  Random Forest            0.156831\n",
       "4    ROE(자기자본이익률)  Random Forest            0.155033\n",
       "5          주식수_취득  Random Forest            0.080213\n",
       "6          주식수_처분  Random Forest            0.066407"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중요도에 따라 정렬\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Feature_Importance', ascending=False)\n",
    "\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자본총계(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>부채총계(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.167988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자산총계(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.167529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>당기순이익(요약)(백만원)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.156831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROE(자기자본이익률)</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.155033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>주식수_취득</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.080213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>주식수_처분</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.066407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature          Model  Feature_Importance\n",
       "2   자본총계(요약)(백만원)  Random Forest            0.206000\n",
       "1   부채총계(요약)(백만원)  Random Forest            0.167988\n",
       "0   자산총계(요약)(백만원)  Random Forest            0.167529\n",
       "3  당기순이익(요약)(백만원)  Random Forest            0.156831\n",
       "4    ROE(자기자본이익률)  Random Forest            0.155033\n",
       "5          주식수_취득  Random Forest            0.080213\n",
       "6          주식수_처분  Random Forest            0.066407"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
