# Paper Output Mapping - Code to Results

This document provides a precise mapping between the analysis code and paper outputs.

---

## ğŸ“Š Complete Output Mapping

### Tables

| Output | Cell(s) | Description | Key Variables |
|--------|---------|-------------|---------------|
| **Table 1** | 5 | Descriptive statistics | All variables: date ranges, quartiles, means |
| **Table 2** | 16 | Behavior analysis by Tobin Q | Behavior types: Burned, Disposed_Slower, Long-term Holding |
| **Table 3** | 28 | Cluster summary (k=3) | Mean values per cluster for all 6 features |
| **Table 4** | 33 | Cluster-Behavior cross-tabulation | Distribution matrix: 3 clusters Ã— 3 behaviors |
| **Table 5** | 49 | ML model performance | Accuracy: AdaBoost, XGBoost, GB, RF |
| **Table 6** | 57-59 | Feature importance: Burned | Top features predicting burned shares |
| **Table 7** | 57, 60 | Feature importance: Disposed_Slower | Top features predicting slower disposal |
| **Table 8** | 57, 61 | Feature importance: Long-term Holding | Top features predicting long-term holding |
| **Table 9** | 135-136 | Overall feature importance | Aggregated rankings across all models |
| **Table 10** | 128 | Value judgment classification | Undervalued vs. Fairly valued distribution |

### Figures

| Output | Cell(s) | Type | Description |
|--------|---------|------|-------------|
| **Figure 1** | 22 | Line plot | Elbow plot: Inertia vs. k (1-10) for optimal cluster selection |
| **Figure 2** | 23 | Score plot | Silhouette score for k=3 clustering solution |
| **Figure 3** | 33 | Distribution plot | Cluster-Behavior distribution visualization |
| **Figure 4** | 57-62 | Bar chart | Feature importance by behavior type (3 separate charts) |
| **Figure 5** | 49 | Bar chart | Model performance comparison (accuracy scores) |

---

## ğŸ” Detailed Cell-by-Cell Breakdown

### Section 1: Data Loading (Cell 0)
```
Input: KOSPI/KOSDAQ Excel files
Output: Merged dataset
Purpose: Load and combine raw data
```

### Section 2: Descriptive Statistics â†’ Table 1 (Cells 2-5)
```
Cell 2: Load data
Cell 3: Check data structure
Cell 4: Calculate date ranges, unique values
Cell 5: Generate quartiles and means â†’ TABLE 1
```

### Section 3: Data Preprocessing (Cells 9-13)
```
Cell 9: Remove missing values
Cell 10: Remove 'Unknown' behaviors
Cell 11: One-hot encode firm size
Cell 12: Clean dataset
Cell 13: Verify cleaning
```

### Section 4: Behavior Analysis â†’ Table 2 (Cell 16)
```
Cell 16: Group by Behavior, calculate Tobin Q â†’ TABLE 2
```

### Section 5: Feature Selection (Cells 18-21)
```
Cell 18: Select 6 clustering features
Cell 19: Create feature matrix X
Cell 20: Apply StandardScaler
Cell 21: Verify scaling
```

### Section 6: Clustering â†’ Figures 1-2, Table 3 (Cells 22-28)
```
Cell 22: Elbow plot (k=1 to 10) â†’ FIGURE 1
Cell 23: Calculate silhouette score â†’ FIGURE 2
Cell 24: Fit KMeans(k=3)
Cell 25: Assign cluster labels
Cell 26: Verify cluster distribution
Cell 27: Prepare cluster summary
Cell 28: Calculate cluster means â†’ TABLE 3
```

### Section 7: Cluster-Behavior â†’ Table 4, Figure 3 (Cell 33)
```
Cell 33:
  - Cross-tabulate clusters Ã— behaviors â†’ TABLE 4
  - Visualize distribution â†’ FIGURE 3
```

### Section 8: ML Models â†’ Table 5, Figure 5 (Cells 38-49)
```
Cell 38: Prepare features and targets
Cell 42: Create binary labels per cluster
Cell 43: Split train/test (70/30)
Cell 47: Initialize 4 models
Cell 48: Train all models
Cell 49:
  - Calculate accuracy scores â†’ TABLE 5
  - Plot performance comparison â†’ FIGURE 5
```

### Section 9: Feature Importance â†’ Tables 6-8, Figure 4 (Cells 57-62)
```
Cell 57: Train models by behavior type
Cell 58: Extract all feature importances
Cell 59: Feature importance for Burned â†’ TABLE 6
Cell 60: Feature importance for Disposed_Slower â†’ TABLE 7
Cell 61: Feature importance for Long-term Holding â†’ TABLE 8
Cell 62: Visualize feature importance â†’ FIGURE 4
```

### Section 10: Value Judgment â†’ Table 10 (Cells 99-128)
```
Cell 99: Define value judgment criteria
Cell 106: Create value judgment labels
Cell 108: Train classification models
Cell 128: Calculate label frequencies â†’ TABLE 10
```

### Section 11: Final Feature Importance â†’ Table 9 (Cells 135-136)
```
Cell 135: Aggregate feature importance
Cell 136: Sort and rank features â†’ TABLE 9
```

---

## ğŸ“ˆ Output Files Generated

### CSV Files (in 02_Paper_Results/output_data/):

| File | Generated By | Content |
|------|--------------|---------|
| cluster4_summary.csv | Cell 28 (earlier k=4 version) | Cluster mean values |
| labelfeature.csv | Cells 57-61 | Feature importance details |
| label_freq.csv | Cell 128 | Behavior and value judgment frequencies |
| Final_Processed_Data_2024-01-10.csv | Multiple cells | Complete processed dataset |

### Figures (in 02_Paper_Results/figures/):

| File | Generated By | Format |
|------|--------------|--------|
| ìì‚¬ì£¼_2023_12_07_ê·¸ë¦¼1.docx | Cell 22 | Elbow plot |
| ìì‚¬ì£¼_2023_12_07_ê·¸ë¦¼2.docx | Cell 23 | Silhouette score |
| ìì‚¬ì£¼_2023_12_07_ê·¸ë¦¼3.docx | Cell 33 | Cluster-Behavior distribution |
| ìì‚¬ì£¼_2023_12_07_ê·¸ë¦¼4.docx | Cells 57-62 | Feature importance charts |
| ìì‚¬ì£¼_2023_12_07_ê·¸ë¦¼5.docx | Cell 49 | Model performance |

### Tables (in 02_Paper_Results/tables/):

| File | Generated By | Content |
|------|--------------|---------|
| ìì‚¬ì£¼_2023_12_07_í‘œ1.docx | Cell 5 | Descriptive statistics |
| ìì‚¬ì£¼_2023_12_07_í‘œ2.docx | Cell 16 | Tobin Q by behavior |
| ìì‚¬ì£¼_2023_12_07_í‘œ3.docx | Cell 28 | Cluster summary |
| ìì‚¬ì£¼_2023_12_07_í‘œ4.docx | Cell 33 | Cluster-Behavior cross-tab |
| ìì‚¬ì£¼_2023_12_07_í‘œ5.docx | Cell 49 | Model performance |
| ìì‚¬ì£¼_2023_12_07_í‘œ6.docx | Cells 57-59 | FI: Burned |
| ìì‚¬ì£¼_2023_12_07_í‘œ7.docx | Cells 57, 60 | FI: Disposed_Slower |
| ìì‚¬ì£¼_2023_12_07_í‘œ8.docx | Cells 57, 61 | FI: Long-term Holding |
| ìì‚¬ì£¼_2023_12_07_í‘œ9.docx | Cells 135-136 | Overall feature importance |
| ìì‚¬ì£¼_2023_12_07_í‘œ10.docx | Cell 128 | Value judgment |

---

## ğŸ¯ Essential Cells Summary

**Minimum 41 code cells needed to reproduce all outputs:**

```python
[0, 2, 3, 4, 5, 9, 10, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33,
 38, 42, 43, 47, 48, 49, 57, 58, 59, 60, 61, 62, 99, 106, 108, 128, 135, 136]
```

**Breakdown by section:**
- Data loading: 1 cell
- Table 1: 4 cells
- Preprocessing: 5 cells
- Table 2: 1 cell
- Feature prep: 4 cells
- Figures 1-2, Table 3: 7 cells
- Table 4, Figure 3: 1 cell
- Table 5, Figure 5: 6 cells
- Tables 6-8, Figure 4: 6 cells
- Table 10: 3 cells
- Table 9: 2 cells

**Total: 40 essential cells + 1 loading cell = 41 cells**

---

## ğŸ”§ Key Parameters

### Clustering Configuration:
```python
n_clusters = 3
random_state = 0
scaler = StandardScaler()
```

### ML Model Configuration:
```python
random_state = 0  # For all models
test_size = 0.3
stratify = True
```

### Feature Set:
```python
features = [
    'ìì‚°ì´ê³„(ìš”ì•½)(ë°±ë§Œì›)',      # Total Assets
    'ë¶€ì±„ì´ê³„(ìš”ì•½)(ë°±ë§Œì›)',      # Total Liabilities
    'ìë³¸ì´ê³„(ìš”ì•½)(ë°±ë§Œì›)',      # Total Equity
    'ë‹¹ê¸°ìˆœì´ìµ(ìš”ì•½)(ë°±ë§Œì›)',    # Net Income
    'ROE(ìê¸°ìë³¸ì´ìµë¥ )',        # Return on Equity
    'êµ¬ë¶„'                         # Market Classification
]
```

---

## ğŸ“Œ Quick Reference

### Need to regenerate Table 1?
â†’ Run cells 0, 2, 3, 4, 5

### Need to regenerate Clustering analysis?
â†’ Run cells 0, 9-13, 18-28

### Need to regenerate ML models?
â†’ Run cells 0, 9-13, 18-28, 38, 42, 43, 47, 48, 49

### Need to regenerate Feature Importance?
â†’ Run cells 0, 9-13, 18-28, 57-62

### Need to regenerate ALL outputs?
â†’ Run all 41 essential cells in sequence

---

**Document Version**: 1.0
**Last Updated**: 2026-01-07
**Corresponds to**: Final_Paper_Analysis_10Tables_5Figures.ipynb
